{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "import pm4py\n",
    "import sys\n",
    "sys.path.append('../') \n",
    "from utils.utilities import Utilities\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "wilcoxon_signed_rank_test = Utilities.wilcoxon_signed_rank_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c87430416d4d86b9662240722185fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/7065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../data/PermitLog.xes'\n",
    "log = pm4py.read_xes(file_path, progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd815ab269e64fbe9f8d541fb441341c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db547847998a4cef8a8f1e35674c6534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d689c25f61468da97ee740f7ff1382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  {'perc_fit_traces': 0.0, 'average_trace_fitness': 0.4175010080427763, 'log_fitness': 0.41989689325938545, 'percentage_of_fitting_traces': 0.0}\n",
      "Simplicity:  0.41904761904761906\n",
      "Generalization:  0.8552671808747483\n",
      "Fitness score: 0.41989689325938545\n",
      "Mixed score: 0.5647372310605843\n"
     ]
    }
   ],
   "source": [
    "net, initial_marking, final_marking = alpha_miner.apply(log)\n",
    "alpha_model_baseline = (net, initial_marking, final_marking)\n",
    "fitness_score = Utilities.fitness_score(log, alpha_model_baseline)\n",
    "mixed_score = Utilities.mixed_score(log, alpha_model_baseline, verbose=True)\n",
    "\n",
    "print(f'Fitness score: {fitness_score}')\n",
    "print(f'Mixed score: {mixed_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic miner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394bc603c9984dd3a55787aa3a657259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcd2e2afddd4ad9b9cf048614b63b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8063290d5c5d498f8d8a85278b8c2055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  {'perc_fit_traces': 0.6510969568294409, 'average_trace_fitness': 0.8911335458231742, 'log_fitness': 0.8910248238210718, 'percentage_of_fitting_traces': 0.6510969568294409}\n",
      "Simplicity:  0.4786450662739322\n",
      "Generalization:  0.5947986582652351\n",
      "Fitness score: 0.8910248238210718\n",
      "Mixed score: 0.6548228494534131\n"
     ]
    }
   ],
   "source": [
    "net, initial_marking, final_marking = pm4py.discover_petri_net_heuristics(log)\n",
    "heuristic_model_baseline = (net, initial_marking, final_marking)\n",
    "fitness_score = Utilities.fitness_score(log, heuristic_model_baseline)\n",
    "mixed_score = Utilities.mixed_score(log, heuristic_model_baseline, verbose=True)\n",
    "\n",
    "print(f'Fitness score: {fitness_score}')\n",
    "print(f'Mixed score: {mixed_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inductive miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86028489bd144e25b24ceef963ccf831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fb2b59e5de47c18e3e0374960d5997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985f3137e3a84eafb2a8ec9f439176bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness:  {'perc_fit_traces': 100.0, 'average_trace_fitness': 1.0, 'log_fitness': 1.0, 'percentage_of_fitting_traces': 100.0}\n",
      "Simplicity:  0.5946547884187082\n",
      "Generalization:  0.8616797985629043\n",
      "Fitness score: 1.0\n",
      "Mixed score: 0.8187781956605376\n"
     ]
    }
   ],
   "source": [
    "net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(log)\n",
    "inductive_model_baseline = (net, initial_marking, final_marking)\n",
    "fitness_score = Utilities.fitness_score(log, inductive_model_baseline)\n",
    "mixed_score = Utilities.mixed_score(log, inductive_model_baseline, verbose=True)\n",
    "\n",
    "print(f'Fitness score: {fitness_score}')\n",
    "print(f'Mixed score: {mixed_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypeopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_time, start_time, best_model, best_score = None, None, None, None\n",
    "def check_is_time_limit_reached():\n",
    "    \n",
    "    if budget_time == None:\n",
    "        return\n",
    "    \n",
    "    if time.time() - start_time > budget_time:\n",
    "        print(\"Time limit reached\")\n",
    "        raise SystemExit\n",
    "\n",
    "\n",
    "def get_net(params):    \n",
    "    model_name = params['model_name']\n",
    "    del params[\"model_name\"]\n",
    "\n",
    "    if model_name == 'alpha':\n",
    "        net, initial_marking, final_marking = alpha_miner.apply(log)\n",
    "    elif model_name == 'alpha_plus':\n",
    "        net, initial_marking, final_marking =  alpha_miner.apply(log, variant=alpha_miner.Variants.ALPHA_VERSION_PLUS)\n",
    "    elif model_name == 'inductive':\n",
    "        net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(log, **params)\n",
    "    elif model_name == 'heuristic':\n",
    "        net, initial_marking, final_marking = pm4py.discover_petri_net_heuristics(log, **params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return (net, initial_marking, final_marking)\n",
    "\n",
    "def objective(params):\n",
    "    global best_model, best_score\n",
    "    check_is_time_limit_reached()\n",
    "    clear_output()\n",
    "    score_type = params['score_type']\n",
    "    del params[\"score_type\"]\n",
    "\n",
    "    model = get_net(params)\n",
    "    \n",
    "    if score_type == 'fitness':\n",
    "        score = Utilities.fitness_score(log, model)\n",
    "    elif score_type == 'mixed':\n",
    "        score = Utilities.mixed_score(log, model)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown score type: {score_type}\")\n",
    "\n",
    "    if not best_score or score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_space(eval_func_name):\n",
    "    search = [\n",
    "        {\n",
    "            \"model_name\": \"alpha\",\n",
    "            \"score_type\": eval_func_name\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"inductive\",\n",
    "            \"score_type\": eval_func_name,\n",
    "            \"noise_threshold\": hp.uniform(\"noise_threshold\", 0.0, 0.5),\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"heuristic\",\n",
    "            \"score_type\": eval_func_name,\n",
    "            \"dependency_threshold\": hp.uniform(\"dependency_threshold\", 0.0, 0.9),\n",
    "            \"and_threshold\": hp.uniform(\"and_threshold\", 0.0, 0.9),\n",
    "            \"loop_two_threshold\": hp.uniform(\"loop_two_threshold\", 0.0, 0.9),\n",
    "        }\n",
    "    ]\n",
    "    return hp.choice(\"classifier_type\", search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6aed5df7dc4626be4f5d705a8ba7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit reached                                                                    \n",
      "  1%|          | 11/1000 [01:03<1:35:10,  5.77s/trial, best loss: -0.9183239520668016]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "budget_time = 1 * 60 # 15 minutes\n",
    "trials = Trials()\n",
    "search_space = create_search_space('fitness')\n",
    "start_time = time.time()\n",
    "best_hyperparams_fitness = fmin(fn=objective,\n",
    "                        space=search_space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=1000,\n",
    "                        trials=trials)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparams_fitness)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fitness = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ea77e4b6e4e2592c78912ffeb9eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d59c5b18a04622b7bdf9bd4ace6d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wilcoxon Signed-Rank Test (Log Loss):\n",
      "Statistic: 0.0000, P-value: 0.0000\n",
      "The optimized pipeline significantly beats the baseline.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "statistic, p_value = wilcoxon_signed_rank_test(log, inductive_model_baseline, best_model_fitness, \"fitness\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddbc1dd85b7455aae304b334b639169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a426fb2f6340b39a038683a0086d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/1478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit reached                                                                   \n",
      "  0%|          | 4/1000 [01:13<5:04:13, 18.33s/trial, best loss: -0.6499933705388616]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "best_model, best_score = None, None\n",
    "\n",
    "budget_time = 1 * 60 # 15 minutes\n",
    "trials = Trials()\n",
    "search_space = create_search_space('mixed')\n",
    "start_time = time.time()\n",
    "best_hyperparams_mixed = fmin(fn=objective,\n",
    "                        space=search_space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=1000,\n",
    "                        trials=trials)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparams_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_mixed = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87d11b34ef54b4d89fbb26aeb1a697d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746b24ff99484f2dafe5cbaac6655308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed traces ::   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wilcoxon Signed-Rank Test (Log Loss):\n",
      "Statistic: 0.0000, P-value: 0.0000\n",
      "The optimized pipeline significantly beats the baseline.\n"
     ]
    }
   ],
   "source": [
    "statistic, p_value = wilcoxon_signed_rank_test(log, inductive_model_baseline, best_model_mixed, \"fitness\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
